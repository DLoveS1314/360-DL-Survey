## Rotation Equivariant Orientation Estimation for Omnidirectional Localization

- year: 2020

- dataset: SceneCity dataset, and Stanford2D3D dataset
- Abstract: In this work we present a direct 6-DoF camera pose estimation method which alleviates the need for ori- entation augmentation at train time while still supporting any SO(3) rotation at test time.
- Contributions:
(1) We present the first rotation invariant, deep camera position regression network;
(2) We introduce rotation equivariant decoder and a sample efficient classification loss to generate camera rotation estimation in full SO(3) from only one rotation observation in training data, without rotation augmentation;
(3) We evaluate our method on synthetic and real datasets.

<img src="https://github.com/VLISLAB/360-DL-Survey/blob/main/Images/rotation_1.png" width="70%" height="70%">

<img src="https://github.com/VLISLAB/360-DL-Survey/blob/main/Images/rotation_2.png" width="70%" height="70%">




