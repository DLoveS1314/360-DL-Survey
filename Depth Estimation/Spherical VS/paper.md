## Spherical View Synthesis for Self-Supervised 360-degree Depth Estimation

- year: 2019

- dataset: 360-degree stereo dataset 

- Abstract: In this work, we explore spherical view synthesis for learning monocular 360-degree depth in a self-supervised manner and demonstrate its feasibility.
- Contributions:
  (1) The full spherical disparity model is presented using a purely geometric derivation.
(2) A robust supervision scheme is developed for spheri- cal view synthesis using depth-image-based rendering (DIBR) and spherical attention.
(3) Unlike inefficient and resource consuming spherical learning approaches, our network design incorporates a straightforward way to make our model aware of its spherical nature.
(4) Besides offering a large 360o stereo dataset, our work is uniquely posed to compare the effectiveness of view synthesis and direct supervision. We perform a fair and consistent evaluation and present its results.


<img src="https://github.com/VLISLAB/360-DL-Survey/blob/main/Images/Spherical VS_1.png" width="70%" height="70%">
<img src="https://github.com/VLISLAB/360-DL-Survey/blob/main/Images/Spherical VS_2.png" width="70%" height="70%">

- Resultsï¼š
  <img src="https://github.com/VLISLAB/360-DL-Survey/blob/main/Images/Spherical VS_exp1.png" width="50%" height="50%">

-Analysis: This work presents a full spherical disparity model for self-supervised depth prediction in 360 domain. In addition, they also provide a relative dataset.
