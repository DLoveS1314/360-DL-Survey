## 360-Indoor: Towards Learning Real-World Objects in 360◦ Indoor Equirectangular Images

- year: WACV 2020

- dataset：  **( 360-Indoor)**  

- abstract: we present a real-world 360◦ panoramic object detection dataset, 360-Indoor, which is a new benchmark for visual object detection and class recognition in 360◦ indoor images. 360-Indoor has several distinct properties: (1) the largest category number (37 labels in total). (2) the most complete annotations on average (27 bounding boxes per image). The selected 37 objects are all common in indoor scene. With around 3k images and 90k labels in total, 360-Indoor achieves the largest dataset for detection in 360◦ images.

![image](https://github.com/VLISLAB/360-DL-Survey/blob/main/Images/dataset/360-Indoor_example.png)

![image](https://github.com/VLISLAB/360-DL-Survey/blob/main/Images/dataset/360-Indoor-distribution.png)

![image](https://github.com/VLISLAB/360-DL-Survey/blob/main/Images/dataset/360-Indoor-category.png)

- Contributions:

(1) We collects the first object detection and classification dataset on 360◦ domain which contains 3k equirect-angular indoor images and 90k BFoVs annotations
   among 37 categories.
(2) We comprehensively evaluate three different object de-tection models on the proposed 360-Indoor dataset.
The results show that standard object detection meth-ods train on the proposed dataset do have large im-provements than using NFoVs

- approachs (1. one-stage object detection approach (e.g., YOLOv3) and 
2.two-stage object detection approach (e.g., Faster R-CNN and FPN).)

![image](https://github.com/VLISLAB/360-DL-Survey/blob/main/Images/dataset/360-indoor-approach.png)


- results：
![image](https://github.com/VLISLAB/360-DL-Survey/blob/main/Images/dataset/360-Indoor_result.png)

