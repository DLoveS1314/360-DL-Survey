## 360-degree Video Gaze Behaviour: A Ground-Truth Data Set and a Classification Algorithm for Eye Movements

- year: 2019

- abstract: we aimed to provide a starting point for comprehensive eye movement classification in an unrestrained head setting. To this end, we selected a very generic stimulus domain (naturalistic 360◦ video), where we can, however, retain auxiliary information such as precise head rotation.


- Contributions:
1) we collect, partially annotate, and make publicly available a new eye tracking data set, which consists of 13 participants viewing 15 video clips that are recorded in 360◦ 

2) we propose a new two-stage pipeline for ground truth annotation of the traditional fixations, saccades, smooth pursuits, as well as (optokinetic) nystagmus, vestibuloocular reflex, and pursuit of moving objects performed exclusively via the movement of the head.

3) we develop and test a simple proof-of-concept algorithm for automatic classification of all the eye movement types in our data set based on their operational definitions that were used for manual annotation.

![image](https://github.com/VLISLAB/360-DL-Survey/blob/main/Images/360videogazeresult.png)
![image](https://github.com/VLISLAB/360-DL-Survey/blob/main/Images/360videogazeresult1.png)
![image](https://github.com/VLISLAB/360-DL-Survey/blob/main/Images/360videogazeresult1.png)


