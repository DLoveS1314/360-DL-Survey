## 360-aware saliency estimation with conventional image saliency predictors
- year: 2018
- dataset: Salient360!

- abstract:  we propose several ways of interpreting equirectangular images and 
analyse how these affect the quality of the resulting saliency maps. We perform our experiments
with three popular conventional saliency predictors and achieve excellent results on the ‘‘Salient360!’’ Grand Challenge data set.

- contributions: 
(1) We proposed a range of transformations of the input equirectangular images, which we call ‘‘interpretations’’, that allow us to predict 360◦ saliency 
using any existing 2D attention model.
(2) Our approach demonstrated excellent results on a data set of omnidirectional images without any training or parameter adjustments. 
(3) Our approach does not require any additional training and can be used with any conventional pre-trained saliency model.

- Framework:

![image](https://github.com/VLISLAB/360-DL-Survey/blob/main/Images/saliency%20prediction/360-aware_framework.png)

- results:

![image](https://github.com/VLISLAB/360-DL-Survey/blob/main/Images/saliency%20prediction/360-aware_result.png)
